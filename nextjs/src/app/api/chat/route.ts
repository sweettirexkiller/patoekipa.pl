import { OpenAI } from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'test_key',
})

export async function POST(req: NextRequest) {
  try {
    const { messages } = await req.json()

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'Messages array is required' },
        { status: 400 }
      )
    }

    // Add system message to provide context about Patoekipa
    const systemMessage = {
      role: 'system' as const,
      content: `JesteÅ› asystentem AI zespoÅ‚u Patoekipa - polskiej firmy specjalizujÄ…cej siÄ™ w tworzeniu nowoczesnych aplikacji webowych, mobilnych i systemÃ³w. 

Patoekipa oferuje:
- Tworzenie aplikacji webowych (React, Next.js, Vue.js)
- Aplikacje mobilne (Flutter, React Native)
- Systemy backend (Node.js, Python, Java)
- RozwiÄ…zania AI i Machine Learning
- Konsultacje techniczne i architektura systemÃ³w
- DevOps i wdroÅ¼enia w chmurze

ZespÃ³Å‚ skÅ‚ada siÄ™ z doÅ›wiadczonych programistÃ³w: MichaÅ‚a, Piotra, Tomasza i Anny.

Odpowiadaj profesjonalnie, pomocnie i w jÄ™zyku polskim. JeÅ›li uÅ¼ytkownik pyta o usÅ‚ugi, ceny lub szczegÃ³Å‚y projektÃ³w, zaproponuj mu kontakt z zespoÅ‚em przez formularz na stronie lub bezpoÅ›rednio.

BÄ…dÅº konkretny i merytoryczny, ale zachowaj przyjazny ton. JeÅ›li nie znasz odpowiedzi na pytanie techniczne, przyznaj siÄ™ do tego i zasugeruj konsultacjÄ™ z ekspertami zespoÅ‚u.`
    }

    const allMessages = [systemMessage, ...messages]

    console.log('GEkkiiiii');
    console.log(process.env.OPENAI_API_KEY);

    // Check if we have a real API key (starts with sk-)
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'test_key_for_development' || !process.env.OPENAI_API_KEY.startsWith('sk-')) {
      // Return a mock streaming response for testing
      const encoder = new TextEncoder()
      const mockResponse = "DziÄ™kujÄ™ za wiadomoÅ›Ä‡! ğŸ¤–\n\nJestem asystentem AI zespoÅ‚u **Patoekipa**. Obecnie dziaÅ‚am w trybie demonstracyjnym.\n\nAby w peÅ‚ni korzystaÄ‡ z moich moÅ¼liwoÅ›ci, zespÃ³Å‚ musi skonfigurowaÄ‡ prawdziwy klucz API OpenAI.\n\n### Co mogÄ™ robiÄ‡:\n- âœ… OdpowiadaÄ‡ na pytania o usÅ‚ugi Patoekipa\n- âœ… PomagaÄ‡ w wyborze technologii\n- âœ… UdzielaÄ‡ porad technicznych\n- âœ… FormatowaÄ‡ odpowiedzi w **Markdown**\n\n```javascript\n// PrzykÅ‚ad kodu\nconsole.log('Witaj w Patoekipa!');\n```\n\nSkontaktuj siÄ™ z zespoÅ‚em, aby uzyskaÄ‡ peÅ‚nÄ… funkcjonalnoÅ›Ä‡! ğŸš€"
      
      const readable = new ReadableStream({
        async start(controller) {
          // Simulate streaming by sending chunks
          const words = mockResponse.split(' ')
          for (let i = 0; i < words.length; i++) {
            const chunk = (i === 0 ? words[i] : ' ' + words[i])
            const data = `data: ${JSON.stringify({ content: chunk })}\n\n`
            controller.enqueue(encoder.encode(data))
            // Add small delay to simulate real streaming
            await new Promise(resolve => setTimeout(resolve, 50))
          }
          controller.enqueue(encoder.encode('data: [DONE]\n\n'))
          controller.close()
        },
      })

      return new Response(readable, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      })
    }

    const stream = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: allMessages,
      stream: true,
      max_tokens: 500,
      temperature: 0.7,
    })

    // Create a readable stream for the response
    const encoder = new TextEncoder()
    const readable = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || ''
            if (content) {
              const data = `data: ${JSON.stringify({ content })}\n\n`
              controller.enqueue(encoder.encode(data))
            }
          }
          // Send end signal
          controller.enqueue(encoder.encode('data: [DONE]\n\n'))
          controller.close()
        } catch (error) {
          console.error('Streaming error:', error)
          controller.error(error)
        }
      },
    })

    return new Response(readable, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })
  } catch (error) {
    console.error('OpenAI API error:', error)
    return NextResponse.json(
      { error: 'Failed to process chat request' },
      { status: 500 }
    )
  }
} 